"""
í•˜ì´ë¸Œë¦¬ë“œ ì¸í…íŠ¸ ë¶„ë¥˜ê¸° (Hybrid Intent Classifier)
=====================================

3ë‹¨ê³„ í´ë°± ì‹œìŠ¤í…œ:
1. í‚¤ì›Œë“œ ë§¤ì¹­ (0ms) - 90% ì¿¼ë¦¬ ì²˜ë¦¬
2. ì„ë² ë”© ìœ ì‚¬ë„ (~100ms) - ì• ë§¤í•œ í‘œí˜„
3. LLM ë¶„ë¥˜ (~1s) - ë³µì¡í•œ ì¿¼ë¦¬

ì‚¬ìš©ë²•:
    classifier = HybridIntentClassifier()
    result = await classifier.classify("ì‚¼ì„±ì „ì ì˜¤ëŠ˜ ì£¼ê°€ ì•Œë ¤ì¤˜")
    # {'intent': 'stock_price', 'confidence': 0.95, 'method': 'keyword', ...}
"""

import json
import re
import os
from typing import Optional, Dict, Any, List, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import asyncio

# ì„ë² ë”©ìš© (ì„ íƒì )
try:
    import numpy as np
    from sentence_transformers import SentenceTransformer
    EMBEDDING_AVAILABLE = True
except ImportError:
    EMBEDDING_AVAILABLE = False
    print("âš ï¸ sentence-transformers ë¯¸ì„¤ì¹˜ - ì„ë² ë”© ê¸°ë°˜ ë¶„ë¥˜ ë¹„í™œì„±í™”")

# LLMìš© (ì„ íƒì )
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸ google-generativeai ë¯¸ì„¤ì¹˜ - LLM ë¶„ë¥˜ ë¹„í™œì„±í™”")


@dataclass
class ClassificationResult:
    """ë¶„ë¥˜ ê²°ê³¼"""
    intent: str
    confidence: float
    method: str  # 'keyword', 'embedding', 'llm'
    parameters: Dict[str, Any] = field(default_factory=dict)
    endpoint: str = ""
    requires_login: bool = False
    latency_ms: float = 0.0


class IntentConfig:
    """ì¸í…íŠ¸ ì„¤ì • - api_schema.json ê¸°ë°˜"""

    INTENTS = {
        # ì£¼ì‹ ê¸°ë³¸
        "stock_price": {
            "keywords": ["ì£¼ê°€", "ì¢…ê°€", "ì‹œì„¸", "ohlcv", "ê°€ê²©", "ì–¼ë§ˆ", "ì‹œê°€", "ê³ ê°€", "ì €ê°€", "ê±°ë˜ëŸ‰"],
            "endpoint": "/api/stocks/ohlcv",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ì£¼ì‹ ê°€ê²© ì¡°íšŒ (OHLCV)"
        },
        "market_cap": {
            "keywords": ["ì‹œê°€ì´ì•¡", "ì‹œì´", "ì´ì•¡", "ë§ˆì¼“ìº¡"],
            "endpoint": "/api/stocks/market-cap",
            "requires_login": False,
            "parameters": ["market", "date"],
            "description": "ì‹œê°€ì´ì•¡ ì¡°íšŒ"
        },
        "fundamental": {
            "keywords": ["per", "pbr", "ë°°ë‹¹", "ìˆ˜ìµë¥ ", "eps", "bps", "dps", "ê¸°ë³¸ì "],
            "endpoint": "/api/stocks/fundamental",
            "requires_login": True,
            "parameters": ["market", "date"],
            "description": "ê¸°ë³¸ ì§€í‘œ (PER/PBR/ë°°ë‹¹)"
        },
        "investor_trading": {
            "keywords": ["íˆ¬ìì", "ë§¤ë§¤ë™í–¥", "ì™¸êµ­ì¸", "ê¸°ê´€", "ê°œì¸", "ìˆœë§¤ìˆ˜", "ìˆœë§¤ë„"],
            "endpoint": "/api/stocks/investor-trading",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "íˆ¬ììë³„ ë§¤ë§¤ë™í–¥"
        },
        "foreign_holding": {
            "keywords": ["ì™¸êµ­ì¸ë³´ìœ ", "ì™¸êµ­ì¸ì§€ë¶„", "ì™¸ì¸ë³´ìœ ", "ì™¸ì¸ì§€ë¶„", "ì™¸êµ­ì¸ ë³´ìœ ìœ¨", "ì™¸êµ­ì¸ ë³´ìœ ", "ì™¸ì¸ ë³´ìœ ìœ¨"],
            "endpoint": "/api/stocks/foreign-holding",
            "requires_login": True,
            "parameters": ["date", "market"],
            "description": "ì™¸êµ­ì¸ ë³´ìœ  í˜„í™©"
        },

        # ETF
        "etf_list": {
            "keywords": ["etf", "ìƒì¥ì§€ìˆ˜í€ë“œ", "etfëª©ë¡", "etfë¦¬ìŠ¤íŠ¸"],
            "endpoint": "/api/etf/all",
            "requires_login": False,
            "parameters": ["date"],
            "description": "ETF ì „ì¢…ëª© ì¡°íšŒ"
        },
        "etf_price": {
            "keywords": ["etfê°€ê²©", "etfì‹œì„¸", "etfì¢…ê°€"],
            "endpoint": "/api/etf/ohlcv",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ETF ê°€ê²© ì¡°íšŒ"
        },
        "etf_pdf": {
            "keywords": ["etfêµ¬ì„±", "pdf", "í¬íŠ¸í´ë¦¬ì˜¤", "etfì¢…ëª©"],
            "endpoint": "/api/etf/pdf",
            "requires_login": False,
            "parameters": ["ticker", "date"],
            "description": "ETF PDF(êµ¬ì„±ì¢…ëª©)"
        },

        # ETN
        "etn_list": {
            "keywords": ["etn", "ìƒì¥ì§€ìˆ˜ì¦ê¶Œ", "etnëª©ë¡"],
            "endpoint": "/api/etn/all",
            "requires_login": False,
            "parameters": ["date"],
            "description": "ETN ì „ì¢…ëª© ì¡°íšŒ"
        },

        # ELW
        "elw_list": {
            "keywords": ["elw", "ì£¼ì‹ì›ŒëŸ°íŠ¸ì¦ê¶Œ", "ì›ŒëŸ°íŠ¸"],
            "endpoint": "/api/elw/all",
            "requires_login": False,
            "parameters": ["date"],
            "description": "ELW ì „ì¢…ëª© ì¡°íšŒ"
        },

        # ê³µë§¤ë„
        "short_selling": {
            "keywords": ["ê³µë§¤ë„", "ìˆ", "ëŒ€ì°¨", "ì°¨ì…", "ëŒ€ì£¼"],
            "endpoint": "/api/short-selling/trading",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ê³µë§¤ë„ ê±°ë˜ í˜„í™©"
        },
        "short_balance": {
            "keywords": ["ê³µë§¤ë„ì”ê³ ", "ìˆì”ê³ ", "ëŒ€ì°¨ì”ê³ "],
            "endpoint": "/api/short-selling/balance",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ê³µë§¤ë„ ì”ê³  í˜„í™©"
        },

        # ì§€ìˆ˜
        "index_price": {
            "keywords": ["ì§€ìˆ˜", "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ì¸ë±ìŠ¤", "kospi", "kosdaq", "ì½”ìŠ¤í”¼200", "ì½”ìŠ¤ë‹¥150", "krx100", "krx300"],
            "endpoint": "/api/index/ohlcv",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ì§€ìˆ˜ ì‹œì„¸ ì¡°íšŒ"
        },
        "index_fundamental": {
            "keywords": ["ì§€ìˆ˜per", "ì§€ìˆ˜pbr", "ì§€ìˆ˜ë°°ë‹¹"],
            "endpoint": "/api/index/fundamental",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ì§€ìˆ˜ ê¸°ë³¸ ì§€í‘œ"
        },

        # ì„ ë¬¼/ì˜µì…˜
        "futures_price": {
            "keywords": ["ì„ ë¬¼", "futures", "ì½”ìŠ¤í”¼200ì„ ë¬¼"],
            "endpoint": "/api/futures/ohlcv",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ì„ ë¬¼ ê°€ê²© ì¡°íšŒ"
        },
        "options_price": {
            "keywords": ["ì˜µì…˜", "options", "ì½œì˜µì…˜", "í’‹ì˜µì…˜"],
            "endpoint": "/api/options/ohlcv",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ì˜µì…˜ ê°€ê²© ì¡°íšŒ"
        },

        # ì±„ê¶Œ
        "bond_price": {
            "keywords": ["ì±„ê¶Œ", "êµ­ì±„", "íšŒì‚¬ì±„", "bond"],
            "endpoint": "/api/bond/ohlcv",
            "requires_login": False,
            "parameters": ["ticker", "start_date", "end_date"],
            "description": "ì±„ê¶Œ ê°€ê²© ì¡°íšŒ"
        },

        # KRX BLD
        "krx_bld": {
            "keywords": ["bld", "krxë°ì´í„°", "krxì¡°íšŒ", "ìƒì„¸ë°ì´í„°"],
            "endpoint": "/api/krx/bld",
            "requires_login": True,
            "parameters": ["bld_id", "params"],
            "description": "KRX BLD ë°ì´í„° ì¡°íšŒ"
        },

        # ìƒíƒœ
        "server_status": {
            "keywords": ["ìƒíƒœ", "status", "ì„œë²„", "ë¡œê·¸ì¸ìƒíƒœ"],
            "endpoint": "/api/status",
            "requires_login": False,
            "parameters": [],
            "description": "ì„œë²„ ìƒíƒœ í™•ì¸"
        },

        # í‹°ì»¤ ê²€ìƒ‰
        "ticker_search": {
            "keywords": ["í‹°ì»¤", "ì¢…ëª©ì½”ë“œ", "ì½”ë“œê²€ìƒ‰", "ticker"],
            "endpoint": "/api/ticker/search",
            "requires_login": False,
            "parameters": ["query", "market"],
            "description": "í‹°ì»¤ ê²€ìƒ‰"
        },

        # ì¢…í•© ë¶„ì„
        "comprehensive_analysis": {
            "keywords": ["ë¶„ì„", "ì¢…í•©", "ì „ì²´", "ë¦¬í¬íŠ¸", "ìš”ì•½"],
            "endpoint": "MULTI",  # ì—¬ëŸ¬ API ì¡°í•©
            "requires_login": True,
            "parameters": ["ticker"],
            "description": "ì¢…í•© ë¶„ì„ (ì—¬ëŸ¬ API ì¡°í•©)"
        },
    }

    # í‹°ì»¤ ì‚¬ì „
    TICKER_DICT = {
        # ì‚¼ì„±ê·¸ë£¹
        "ì‚¼ì„±ì „ì": "005930", "ì‚¼ì„±sdi": "006400", "ì‚¼ì„±ë¬¼ì‚°": "028260",
        "ì‚¼ì„±ìƒëª…": "032830", "ì‚¼ì„±í™”ì¬": "000810", "ì‚¼ì„±ì—ìŠ¤ë””ì—ìŠ¤": "018260",
        # SKê·¸ë£¹
        "skí•˜ì´ë‹‰ìŠ¤": "000660", "skí…”ë ˆì½¤": "017670", "skì´ë…¸ë² ì´ì…˜": "096770",
        "sk": "034730", "skìŠ¤í€˜ì–´": "402340",
        # í˜„ëŒ€ì°¨ê·¸ë£¹
        "í˜„ëŒ€ì°¨": "005380", "ê¸°ì•„": "000270", "í˜„ëŒ€ëª¨ë¹„ìŠ¤": "012330",
        "í˜„ëŒ€ê¸€ë¡œë¹„ìŠ¤": "086280",
        # LGê·¸ë£¹
        "lgì „ì": "066570", "lgí™”í•™": "051910", "lgì—ë„ˆì§€ì†”ë£¨ì…˜": "373220",
        "lgë””ìŠ¤í”Œë ˆì´": "034220",
        # ê¸°íƒ€ ëŒ€í˜•ì£¼
        "ë„¤ì´ë²„": "035420", "ì¹´ì¹´ì˜¤": "035720", "ì…€íŠ¸ë¦¬ì˜¨": "068270",
        "í¬ìŠ¤ì½”í™€ë”©ìŠ¤": "005490", "kbê¸ˆìœµ": "105560", "ì‹ í•œì§€ì£¼": "055550",
        "í•˜ë‚˜ê¸ˆìœµì§€ì£¼": "086790", "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤": "207940",
        "í˜„ëŒ€ì¤‘ê³µì—…": "329180", "í¬ë˜í”„í†¤": "259960", "ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°": "034020",
        # ì¤‘ì†Œí˜•ì£¼ ì˜ˆì‹œ
        "ì—ì½”í”„ë¡œ": "086520", "ì—ì½”í”„ë¡œë¹„ì— ": "247540", "í¬ìŠ¤ì½”í“¨ì²˜ì— ": "003670",
    }

    # ì§€ìˆ˜ ì‚¬ì „
    INDEX_DICT = {
        "ì½”ìŠ¤í”¼": "1001", "ì½”ìŠ¤í”¼200": "1028", "ì½”ìŠ¤í”¼100": "1034",
        "ì½”ìŠ¤í”¼50": "1035", "ì½”ìŠ¤ë‹¥": "2001", "ì½”ìŠ¤ë‹¥150": "2203",
        "krx100": "5042", "krx300": "5300",
    }

    # ì‹œì¥ ì‚¬ì „
    MARKET_DICT = {
        "ì½”ìŠ¤í”¼": "KOSPI", "kospi": "KOSPI",
        "ì½”ìŠ¤ë‹¥": "KOSDAQ", "kosdaq": "KOSDAQ",
        "ì „ì²´": "ALL", "all": "ALL",
    }


class KeywordMatcher:
    """1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ (ê°€ì¥ ë¹ ë¦„)"""

    def __init__(self):
        self.intents = IntentConfig.INTENTS
        self.ticker_dict = IntentConfig.TICKER_DICT
        self.index_dict = IntentConfig.INDEX_DICT
        self.market_dict = IntentConfig.MARKET_DICT

    def match(self, query: str) -> Optional[ClassificationResult]:
        """
        í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì¸í…íŠ¸ ë¶„ë¥˜

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬

        Returns:
            ClassificationResult or None (ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ)
        """
        import time
        start = time.perf_counter()

        query_lower = query.lower().replace(" ", "")

        # ê° ì¸í…íŠ¸ë³„ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        scores: List[Tuple[str, float, int]] = []  # (intent, score, match_count)

        for intent_id, config in self.intents.items():
            keywords = config["keywords"]
            match_count = 0

            for kw in keywords:
                if kw.lower() in query_lower:
                    match_count += 1

            if match_count > 0:
                # ë§¤ì¹­ëœ í‚¤ì›Œë“œ ìˆ˜ / ì „ì²´ í‚¤ì›Œë“œ ìˆ˜ * ê°€ì¤‘ì¹˜
                score = (match_count / len(keywords)) * (1 + match_count * 0.1)
                scores.append((intent_id, score, match_count))

        if not scores:
            return None

        # ê°€ì¥ ë†’ì€ ì ìˆ˜ ì„ íƒ
        scores.sort(key=lambda x: (-x[1], -x[2]))
        best_intent, best_score, match_count = scores[0]

        # ì‹ ë¢°ë„ ê³„ì‚° (ìµœì†Œ 0.5, ìµœëŒ€ 0.99)
        confidence = min(0.99, max(0.5, best_score))

        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        parameters = self._extract_parameters(query, best_intent)

        config = self.intents[best_intent]
        latency = (time.perf_counter() - start) * 1000

        return ClassificationResult(
            intent=best_intent,
            confidence=confidence,
            method="keyword",
            parameters=parameters,
            endpoint=config["endpoint"],
            requires_login=config["requires_login"],
            latency_ms=latency
        )

    def _extract_parameters(self, query: str, intent: str) -> Dict[str, Any]:
        """ì¿¼ë¦¬ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
        params = {}
        query_lower = query.lower().replace(" ", "")  # ê³µë°± ì œê±°

        # í‹°ì»¤ ì¶”ì¶œ
        for name, code in self.ticker_dict.items():
            if name.replace(" ", "") in query_lower:
                params["ticker"] = code
                params["ticker_name"] = name
                break

        # ì§€ìˆ˜ ì¶”ì¶œ (index ì¸í…íŠ¸ì´ê±°ë‚˜ ì§€ìˆ˜ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì‹œ)
        if "index" in intent or "ì§€ìˆ˜" in query_lower or "ì½”ìŠ¤í”¼" in query_lower or "ì½”ìŠ¤ë‹¥" in query_lower:
            for name, code in self.index_dict.items():
                if name.replace(" ", "") in query_lower:
                    params["ticker"] = code
                    params["index_name"] = name
                    break

        # ì‹œì¥ ì¶”ì¶œ
        for name, code in self.market_dict.items():
            if name in query_lower:
                params["market"] = code
                break

        # ë‚ ì§œ ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´)
        date_patterns = [
            (r"ì˜¤ëŠ˜", datetime.now().strftime("%Y%m%d")),
            (r"ì–´ì œ", (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")),
            (r"(\d{4})[-/]?(\d{2})[-/]?(\d{2})", None),  # YYYY-MM-DD
        ]

        for pattern, default_date in date_patterns:
            if default_date:
                if re.search(pattern, query):
                    params["date"] = default_date
                    break
            else:
                match = re.search(pattern, query)
                if match:
                    params["date"] = "".join(match.groups())
                    break

        return params


class EmbeddingClassifier:
    """2ë‹¨ê³„: ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ë¶„ë¥˜"""

    def __init__(self, model_name: str = "jhgan/ko-sroberta-multitask"):
        if not EMBEDDING_AVAILABLE:
            self.model = None
            self.intent_embeddings = None
            return

        print(f"ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”©: {model_name}")
        self.model = SentenceTransformer(model_name)
        self.intents = IntentConfig.INTENTS

        # ì¸í…íŠ¸ë³„ ëŒ€í‘œ ë¬¸ì¥ ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°
        self.intent_examples = self._build_intent_examples()
        self.intent_embeddings = self._compute_intent_embeddings()
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({len(self.intent_embeddings)}ê°œ ì¸í…íŠ¸)")

    def _build_intent_examples(self) -> Dict[str, List[str]]:
        """ì¸í…íŠ¸ë³„ ëŒ€í‘œ ì¿¼ë¦¬ ì˜ˆì‹œ"""
        return {
            "stock_price": [
                "ì‚¼ì„±ì „ì ì£¼ê°€ ì•Œë ¤ì¤˜",
                "ì˜¤ëŠ˜ SKí•˜ì´ë‹‰ìŠ¤ ì¢…ê°€ê°€ ì–¼ë§ˆì•¼",
                "ë„¤ì´ë²„ ì‹œì„¸ ì¡°íšŒ",
                "ì‚¼ì„±ì „ì ì£¼ê°€",  # í‹°ì»¤ + ì£¼ê°€ íŒ¨í„´
                "í˜„ëŒ€ì°¨ ê°€ê²©",
                "ì¹´ì¹´ì˜¤ ì–¼ë§ˆì•¼",
                "LGì „ì ì˜¤ëŠ˜ ì‹œì„¸",
            ],
            "market_cap": [
                "ì½”ìŠ¤í”¼ ì‹œê°€ì´ì•¡ ìˆœìœ„",
                "ì‹œì´ ìƒìœ„ ì¢…ëª©",
                "ì‹œê°€ì´ì•¡ ìƒìœ„ 10ê°œ",  # ìˆœìœ„/ìƒìœ„ íŒ¨í„´
                "ì½”ìŠ¤ë‹¥ ì‹œì´ ìˆœìœ„",
            ],
            "fundamental": [
                "ì‚¼ì„±ì „ì PERì´ ì–¼ë§ˆì•¼",
                "ì½”ìŠ¤í”¼ PBR í‰ê· ",
                "ë°°ë‹¹ìˆ˜ìµë¥  ë†’ì€ ì¢…ëª©",
            ],
            "investor_trading": [
                "ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì¢…ëª©",
                "ê¸°ê´€ ë§¤ë§¤ë™í–¥",
                "ê°œì¸ íˆ¬ìì ìˆœë§¤ë„",
            ],
            "etf_list": [
                "ETF ì „ì²´ ëª©ë¡",
                "ìƒì¥ì§€ìˆ˜í€ë“œ ë¦¬ìŠ¤íŠ¸",
            ],
            "short_selling": [
                "ê³µë§¤ë„ í˜„í™©",
                "ëŒ€ì°¨ê±°ë˜ ì¡°íšŒ",
            ],
            "index_price": [
                "ì½”ìŠ¤í”¼ ì§€ìˆ˜",
                "ì½”ìŠ¤ë‹¥ ì‹œì„¸",
            ],
            "futures_price": [
                "ì½”ìŠ¤í”¼200 ì„ ë¬¼ ê°€ê²©",
                "ì„ ë¬¼ ì‹œì„¸",
            ],
            "comprehensive_analysis": [
                "ì‚¼ì„±ì „ì ì¢…í•© ë¶„ì„í•´ì¤˜",
                "í˜„ëŒ€ì°¨ ì „ì²´ ë¦¬í¬íŠ¸",
            ],
        }

    def _compute_intent_embeddings(self) -> Dict[str, np.ndarray]:
        """ì¸í…íŠ¸ë³„ ì„ë² ë”© ê³„ì‚°"""
        if not self.model:
            return {}

        embeddings = {}
        for intent, examples in self.intent_examples.items():
            # ì˜ˆì‹œ ë¬¸ì¥ë“¤ì˜ í‰ê·  ì„ë² ë”©
            example_embeddings = self.model.encode(examples)
            embeddings[intent] = np.mean(example_embeddings, axis=0)
        return embeddings

    def classify(self, query: str, threshold: float = 0.6) -> Optional[ClassificationResult]:
        """
        ì„ë² ë”© ìœ ì‚¬ë„ë¡œ ì¸í…íŠ¸ ë¶„ë¥˜

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬
            threshold: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’

        Returns:
            ClassificationResult or None
        """
        if not EMBEDDING_AVAILABLE or not self.model:
            return None

        import time
        start = time.perf_counter()

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_embedding = self.model.encode([query])[0]

        # ê° ì¸í…íŠ¸ì™€ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = {}
        for intent, intent_emb in self.intent_embeddings.items():
            sim = np.dot(query_embedding, intent_emb) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(intent_emb)
            )
            similarities[intent] = float(sim)

        # ìµœê³  ìœ ì‚¬ë„ ì¸í…íŠ¸
        best_intent = max(similarities, key=similarities.get)
        best_sim = similarities[best_intent]

        if best_sim < threshold:
            return None

        config = self.intents.get(best_intent, {})
        latency = (time.perf_counter() - start) * 1000

        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (í‚¤ì›Œë“œ ë§¤ì²˜ ì¬ì‚¬ìš©)
        keyword_matcher = KeywordMatcher()
        params = keyword_matcher._extract_parameters(query, best_intent)

        return ClassificationResult(
            intent=best_intent,
            confidence=best_sim,
            method="embedding",
            parameters=params,
            endpoint=config.get("endpoint", ""),
            requires_login=config.get("requires_login", False),
            latency_ms=latency
        )


class LLMClassifier:
    """3ë‹¨ê³„: LLM ê¸°ë°˜ ë¶„ë¥˜ (ê°€ì¥ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)"""

    def __init__(self):
        if not GEMINI_AVAILABLE:
            self.model = None
            return

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            print("âš ï¸ GEMINI_API_KEY ë¯¸ì„¤ì • - LLM ë¶„ë¥˜ ë¹„í™œì„±í™”")
            self.model = None
            return

        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel("gemini-2.0-flash-exp")
        self.intents = IntentConfig.INTENTS
        print("âœ… Gemini LLM ë¶„ë¥˜ê¸° ì´ˆê¸°í™” ì™„ë£Œ")

    async def classify(self, query: str) -> Optional[ClassificationResult]:
        """
        LLMìœ¼ë¡œ ì¸í…íŠ¸ ë¶„ë¥˜

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬

        Returns:
            ClassificationResult or None
        """
        if not self.model:
            return None

        import time
        start = time.perf_counter()

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        intent_descriptions = "\n".join([
            f"- {intent_id}: {config['description']} (í‚¤ì›Œë“œ: {', '.join(config['keywords'][:3])})"
            for intent_id, config in self.intents.items()
        ])

        prompt = f"""ë‹¹ì‹ ì€ ì£¼ì‹ API ì¸í…íŠ¸ ë¶„ë¥˜ê¸°ì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì¸í…íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.

ê°€ëŠ¥í•œ ì¸í…íŠ¸:
{intent_descriptions}

ì‚¬ìš©ì ì¿¼ë¦¬: "{query}"

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{"intent": "ì¸í…íŠ¸_id", "confidence": 0.0~1.0, "reasoning": "ì´ìœ "}}
"""

        try:
            response = self.model.generate_content(prompt)
            response_text = response.text

            # JSON íŒŒì‹±
            json_match = re.search(r'\{[^}]+\}', response_text)
            if not json_match:
                return None

            result = json.loads(json_match.group())
            intent = result.get("intent")
            confidence = result.get("confidence", 0.7)

            if intent not in self.intents:
                return None

            config = self.intents[intent]
            latency = (time.perf_counter() - start) * 1000

            # íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            keyword_matcher = KeywordMatcher()
            params = keyword_matcher._extract_parameters(query, intent)

            return ClassificationResult(
                intent=intent,
                confidence=confidence,
                method="llm",
                parameters=params,
                endpoint=config.get("endpoint", ""),
                requires_login=config.get("requires_login", False),
                latency_ms=latency
            )

        except Exception as e:
            print(f"âŒ LLM ë¶„ë¥˜ ì˜¤ë¥˜: {e}")
            return None


class HybridIntentClassifier:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ì¸í…íŠ¸ ë¶„ë¥˜ê¸°

    3ë‹¨ê³„ í´ë°±:
    1. í‚¤ì›Œë“œ ë§¤ì¹­ (ì‹ ë¢°ë„ > 0.7)
    2. ì„ë² ë”© ìœ ì‚¬ë„ (ì‹ ë¢°ë„ > 0.6)
    3. LLM ë¶„ë¥˜ (ìµœì¢…)
    """

    def __init__(self,
                 keyword_threshold: float = 0.7,
                 embedding_threshold: float = 0.6,
                 enable_embedding: bool = True,
                 enable_llm: bool = True):
        """
        Args:
            keyword_threshold: í‚¤ì›Œë“œ ë§¤ì¹­ ì‹ ë¢°ë„ ì„ê³„ê°’
            embedding_threshold: ì„ë² ë”© ìœ ì‚¬ë„ ì„ê³„ê°’
            enable_embedding: ì„ë² ë”© ë¶„ë¥˜ í™œì„±í™”
            enable_llm: LLM ë¶„ë¥˜ í™œì„±í™”
        """
        self.keyword_matcher = KeywordMatcher()
        self.keyword_threshold = keyword_threshold
        self.embedding_threshold = embedding_threshold

        # ì„ íƒì  ì´ˆê¸°í™”
        self.embedding_classifier = None
        self.llm_classifier = None

        if enable_embedding and EMBEDDING_AVAILABLE:
            self.embedding_classifier = EmbeddingClassifier()

        if enable_llm and GEMINI_AVAILABLE:
            self.llm_classifier = LLMClassifier()

    async def classify(self, query: str) -> ClassificationResult:
        """
        3ë‹¨ê³„ í´ë°±ìœ¼ë¡œ ì¸í…íŠ¸ ë¶„ë¥˜

        Args:
            query: ì‚¬ìš©ì ì¿¼ë¦¬

        Returns:
            ClassificationResult (í•­ìƒ ë°˜í™˜, ì‹¤íŒ¨ ì‹œ unknown ì¸í…íŠ¸)
        """
        import time
        total_start = time.perf_counter()

        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ë§¤ì¹­ (ê°€ì¥ ë¹ ë¦„)
        keyword_result = self.keyword_matcher.match(query)
        if keyword_result and keyword_result.confidence >= self.keyword_threshold:
            print(f"[OK][Keyword] {keyword_result.intent} (conf: {keyword_result.confidence:.2f}, {keyword_result.latency_ms:.1f}ms)")
            return keyword_result

        # 2ë‹¨ê³„: ì„ë² ë”© ìœ ì‚¬ë„
        if self.embedding_classifier:
            embedding_result = self.embedding_classifier.classify(query, self.embedding_threshold)
            if embedding_result:
                print(f"[OK][Embedding] {embedding_result.intent} (conf: {embedding_result.confidence:.2f}, {embedding_result.latency_ms:.1f}ms)")
                return embedding_result

        # 3ë‹¨ê³„: LLM ë¶„ë¥˜
        if self.llm_classifier:
            llm_result = await self.llm_classifier.classify(query)
            if llm_result:
                print(f"[OK][LLM] {llm_result.intent} (conf: {llm_result.confidence:.2f}, {llm_result.latency_ms:.1f}ms)")
                return llm_result

        # 4ë‹¨ê³„: í´ë°± - í‚¤ì›Œë“œ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜ (ë‚®ì€ ì‹ ë¢°ë„ë¼ë„)
        if keyword_result:
            print(f"[WARN][Fallback-Keyword] {keyword_result.intent} (conf: {keyword_result.confidence:.2f})")
            return keyword_result

        # 5ë‹¨ê³„: ì™„ì „ ì‹¤íŒ¨
        total_latency = (time.perf_counter() - total_start) * 1000
        return ClassificationResult(
            intent="unknown",
            confidence=0.0,
            method="none",
            parameters={},
            endpoint="",
            requires_login=False,
            latency_ms=total_latency
        )

    def classify_sync(self, query: str) -> ClassificationResult:
        """ë™ê¸° ë²„ì „ (asyncio ì—†ì´ ì‚¬ìš©)"""
        return asyncio.run(self.classify(query))


# ==============================================================================
# í…ŒìŠ¤íŠ¸ ë° ë°ëª¨
# ==============================================================================

async def demo():
    """ë°ëª¨ ì‹¤í–‰"""
    import sys
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

    print("=" * 60)
    print("[TEST] Hybrid Intent Classifier Test")
    print("=" * 60)

    # ë¶„ë¥˜ê¸° ì´ˆê¸°í™” (ì„ë² ë”©, LLM ì„ íƒì )
    classifier = HybridIntentClassifier(
        enable_embedding=EMBEDDING_AVAILABLE,
        enable_llm=GEMINI_AVAILABLE
    )

    test_queries = [
        # ëª…í™•í•œ í‚¤ì›Œë“œ (1ë‹¨ê³„ì—ì„œ ì²˜ë¦¬)
        "ì‚¼ì„±ì „ì ì˜¤ëŠ˜ ì£¼ê°€ ì•Œë ¤ì¤˜",
        "ì½”ìŠ¤í”¼ ì‹œê°€ì´ì•¡ ìˆœìœ„",
        "SKí•˜ì´ë‹‰ìŠ¤ PER ì–¼ë§ˆì•¼",
        "ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ í˜„í™©",
        "ETF ì „ì²´ ëª©ë¡ ë³´ì—¬ì¤˜",

        # ì• ë§¤í•œ í‘œí˜„ (2-3ë‹¨ê³„ í•„ìš”)
        "ì‚¼ì„±ì „ì ë¶„ì„í•´ì¤˜",
        "ìš”ì¦˜ ì£¼ì‹ ì–´ë•Œ",
        "í˜„ëŒ€ì°¨ íˆ¬ìí•´ë„ ë ê¹Œ",
    ]

    print("\n[RESULTS] Test Query Classification:\n")

    for query in test_queries:
        print(f"Q: {query}")
        result = await classifier.classify(query)
        print(f"   â†’ ì¸í…íŠ¸: {result.intent}")
        print(f"   â†’ ì‹ ë¢°ë„: {result.confidence:.2f}")
        print(f"   â†’ ë°©ì‹: {result.method}")
        print(f"   â†’ ì—”ë“œí¬ì¸íŠ¸: {result.endpoint}")
        print(f"   â†’ íŒŒë¼ë¯¸í„°: {result.parameters}")
        print(f"   â†’ ì†Œìš”ì‹œê°„: {result.latency_ms:.1f}ms")
        print()

    print("=" * 60)
    print("[DONE] Test Complete")


if __name__ == "__main__":
    asyncio.run(demo())
